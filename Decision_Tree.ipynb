{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBhybEvKHXwgLxRg7cA0ds",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saifulislamsarfaraz/Artificial-Intelligence/blob/main/Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cr0S9uGyv1l",
        "outputId": "f99d35b9-60d2-48c6-f7d7-fc381f96445f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: {'Outlook': {'Sunny': 'No', 'Overcast': 'Yes', 'Rain': 'Yes'}}\n",
            "Prediction: No\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "# Function to calculate entropy\n",
        "def calculate_entropy(data):\n",
        "    labels = data.iloc[:, -1]  # Get the last column (target labels)\n",
        "    label_counts = labels.value_counts()  # Count the frequency of each label (e.g., Yes/No)\n",
        "    total = len(labels)  # Total number of samples\n",
        "    entropy = -sum((count / total) * math.log2(count / total) for count in label_counts)  # Entropy formula\n",
        "    return entropy\n",
        "\n",
        "# Function to calculate information gain\n",
        "def calculate_information_gain(data, attribute):\n",
        "    total_entropy = calculate_entropy(data)  # Entropy of the whole dataset\n",
        "    values = data[attribute].unique()  # Unique values in the attribute (e.g., Sunny, Rain, Overcast for Outlook)\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in values:\n",
        "        subset = data[data[attribute] == value]  # Subset where attribute matches the value\n",
        "        weighted_entropy += (len(subset) / len(data)) * calculate_entropy(subset)  # Weighted entropy calculation\n",
        "\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "# Recursive function to build the decision tree\n",
        "def build_decision_tree(data, features):\n",
        "    labels = data.iloc[:, -1]  # Target column (e.g., Play Tennis)\n",
        "\n",
        "    # Stop conditions\n",
        "    if len(labels.unique()) == 1:  # If all labels are the same (pure subset)\n",
        "        return labels.iloc[0]\n",
        "    if len(features) == 0:  # If no features are left to split\n",
        "        return labels.mode()[0]  # Return the most common label\n",
        "\n",
        "    # Select the best feature\n",
        "    gains = {feature: calculate_information_gain(data, feature) for feature in features}  # Calculate gain for all features\n",
        "    best_feature = max(gains, key=gains.get)  # Feature with the highest information gain\n",
        "\n",
        "    # Create the tree node\n",
        "    tree = {best_feature: {}}  # Start building the tree with the best feature\n",
        "\n",
        "    # Recursively build subtrees\n",
        "    for value in data[best_feature].unique():\n",
        "        subset = data[data[best_feature] == value]  # Subset for each value of the best feature\n",
        "        if subset.empty:  # Handle missing data\n",
        "            tree[best_feature][value] = labels.mode()[0]  # Assign most common label\n",
        "        else:\n",
        "            tree[best_feature][value] = build_decision_tree(\n",
        "                subset, [feat for feat in features if feat != best_feature]\n",
        "            )\n",
        "\n",
        "    return tree\n",
        "\n",
        "# Prediction function\n",
        "def predict(tree, sample):\n",
        "    if not isinstance(tree, dict):  # If the tree node is a label (leaf)\n",
        "        return tree\n",
        "\n",
        "    feature = next(iter(tree))  # Root feature of the current tree\n",
        "    value = sample.get(feature)  # Get the sample's value for this feature\n",
        "    subtree = tree[feature].get(value)  # Find the subtree corresponding to this value\n",
        "\n",
        "    if subtree is None:  # Handle unseen attribute values\n",
        "        return None\n",
        "\n",
        "    return predict(subtree, sample)  # Recur on the subtree\n",
        "\n",
        "# Reduced Dataset\n",
        "data = pd.DataFrame({\n",
        "    \"Day\": [\"D1\", \"D2\", \"D3\", \"D4\", \"D5\"],\n",
        "    \"Outlook\": [\"Sunny\", \"Sunny\", \"Overcast\", \"Rain\", \"Rain\"],\n",
        "    \"Temp\": [\"Hot\", \"Hot\", \"Hot\", \"Mild\", \"Cool\"],\n",
        "    \"Humidity\": [\"High\", \"High\", \"High\", \"High\", \"Normal\"],\n",
        "    \"Wind\": [\"Weak\", \"Strong\", \"Weak\", \"Weak\", \"Weak\"],\n",
        "    \"Play Tennis\": [\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\"]\n",
        "})\n",
        "\n",
        "# Remove the \"Day\" column as it is not a feature\n",
        "features = list(data.columns[1:-1])  # Select features excluding \"Day\" and \"Play Tennis\"\n",
        "data = data.drop(columns=[\"Day\"])  # Drop \"Day\" column as it is irrelevant\n",
        "\n",
        "# Build tree\n",
        "decision_tree = build_decision_tree(data, features)\n",
        "print(\"Decision Tree:\", decision_tree)\n",
        "\n",
        "# Predict a sample\n",
        "sample = {\"Outlook\": \"Sunny\", \"Temp\": \"Cool\", \"Humidity\": \"High\", \"Wind\": \"Strong\"}  # Sample input\n",
        "prediction = predict(decision_tree, sample)  # Predict the class label\n",
        "print(\"Prediction:\", prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "    \"Day\": [\"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"D10\", \"D11\", \"D12\", \"D13\", \"D14\"],\n",
        "    \"Outlook\": [\"Sunny\", \"Sunny\", \"Overcast\", \"Rain\", \"Rain\", \"Rain\", \"Overcast\", \"Sunny\", \"Sunny\", \"Rain\", \"Sunny\", \"Overcast\", \"Overcast\", \"Rain\"],\n",
        "    \"Temp\": [\"Hot\", \"Hot\", \"Hot\", \"Mild\", \"Cool\", \"Cool\", \"Cool\", \"Mild\", \"Cool\", \"Mild\", \"Mild\", \"Mild\", \"Hot\", \"Mild\"],\n",
        "    \"Humidity\": [\"High\", \"High\", \"High\", \"High\", \"Normal\", \"Normal\", \"Normal\", \"High\", \"Normal\", \"Normal\", \"Normal\", \"High\", \"Normal\", \"High\"],\n",
        "    \"Wind\": [\"Weak\", \"Strong\", \"Weak\", \"Weak\", \"Weak\", \"Strong\", \"Strong\", \"Weak\", \"Weak\", \"Weak\", \"Strong\", \"Strong\", \"Weak\", \"Strong\"],\n",
        "    \"Play Tennis\": [\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
        "})"
      ],
      "metadata": {
        "id": "eJlSlJY3LR7f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}